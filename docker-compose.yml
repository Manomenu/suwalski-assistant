# Infrastructure Services for Development
# 
# Strategy: Run infrastructure (Ollama, Databases) here.
# Run the application logic locally (via `uv run` or VS Code) for easier debugging and faster iteration.
# To deploy the full stack, create a separate docker-compose.prod.yml or use profiles.

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama
      - ./scripts/infrastructure/ollama-entrypoint.sh:/entrypoint.sh
    entrypoint: ["/entrypoint.sh"]
    environment:
      - BASE_MODEL=${BASE_MODEL:-ollama/qwen2:0.5b}
    restart: always
    # No profile set means this runs by default (Infrastructure)

  app:
    build: .
    profiles: ["fullstack"]
    depends_on:
      - ollama
    environment:
      - BASE_API_BASE=${BASE_API_BASE:-http://ollama:11434}
      - BASE_MODEL=${BASE_MODEL:-ollama/qwen2:0.5b}
      - BASE_API_KEY=${BASE_API_KEY}
      - VISION_API_BASE=${VISION_API_BASE:-http://ollama:11434}
      - VISION_MODEL=${VISION_MODEL:-ollama/qwen2:0.5b}
      - VISION_API_KEY=${VISION_API_KEY}
      - DISCORD_TOKEN=${DISCORD_TOKEN}
      - DISCORD_CHANNEL_ID=${DISCORD_CHANNEL_ID}
    volumes:
      - .:/app
    command: uv run start

volumes:
  ollama_storage:
